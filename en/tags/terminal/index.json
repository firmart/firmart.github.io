[{"content":"Introduction Some time ago, I switched my daily terminal from kitty to alacritty due to issue regarding CJK input methods1. However, alacritty is known to not support tabs by design. There are at least two ways to enable tabs: through tabbed or tmux. Both are available in Ubuntu 20.04 package manager.\ntabbed tabbed is kind of a wrapper that will equip alacritty with tabs. To open alacritty with tabbed, use the following command:\n1  tabbed alacritty --embed   Some notable keybindings:\n Ctrl+Shift+Ret to open a new tab. Ctrl+Tab or Ctrl+Shift+h / Ctrl+Shift+l to cycle tabs. Ctrl+q to kill a tab.  tmux tmux is probably one of the most-used terminal multiplexer. In tmux jargon, tabs are called windows. You may want to directly work under tmux. To do so, open alacritty with tmux:\n1  alacritty -e tmux   tmux offers a bunch of features and customizability, but essentially, to just try out tmux windows feature, note the following shortcuts:\n Create a window with C-b c. Cycle forward/backward among windows with C-b n / C-b p. Kill a window with C-b \u0026amp; or C-d.  Bonus: Keep only one terminal instance In my opinion, it\u0026rsquo;s not a good idea to keep multiple terminal windows: switching among them is quickly irritating. Personally, I bind Super+T to terminal and keep a single instance by using wmctrl. Concretely, combining up with the above commands:\n  For tabbed.\n1  wmctrl -x -a \u0026#34;tabbed\u0026#34; || tabbed alacritty --embed     For tmux.\n1  wmctrl -x -a \u0026#34;alacritty\u0026#34; || alacritty -e tmux     The commands check if there is a terminal instance, if so focus on it, otherwise create a new instance. You will have to wrap these commands in bash -c '\u0026lt;command\u0026gt;' if you want to bind them in Ubuntu settings (Keyboard shortcuts \u0026gt; Custom shortcuts). I use this tactic to bind the global keybindings I use 99% of the time: namely Super+C for browser, Super+E for Emacs and Super+T for terminal.\nConclusion tabbed is light enough for people needing only tabs and no more. But I noticed some encumbrances making me switched to tmux:\n Keybindings are hardcoded in config.def.h2, although you can easily change it and compile a local version, it might not worth it. Ranger image preview doesn\u0026rsquo;t work anymore. The developpement is kind of inactive3.   They actually work, but the feature is turned off by default. One has to enable it by setting the environment variable GLFW_IM_MODULE=ibus. \u0026#x21a9;\u0026#xfe0e;\n In my case, I bound in Vim C-q as :q! for years and was not ready to change it just for tabbed. \u0026#x21a9;\u0026#xfe0e;\n You might want to check out this fork for better support. \u0026#x21a9;\u0026#xfe0e;\n   ","description":"","id":0,"section":"posts","tags":["terminal","tmux","tabbed","alacritty","kitty","linux"],"title":"Tabs in Alacritty","uri":"https://firminmartin.com/en/posts/2021/03/tabs_in_alacritty/"},{"content":"Introduction It\u0026rsquo;s been half a month that I\u0026rsquo;m gradually writing an Emacs package for notmuch email notification. Although it works fine so far, it misses an important feature which consists to display the subject and the sender name on the notification instead of merely saying \u0026ldquo;2 new messages since last refresh\u0026rdquo;.\nFortunately, probably because the development of the notmuch Emacs frontend, notmuch can speak Lisp S-expression.\nNotmuch show To retrieve header from emails, we need the command notmuch show. Moreover, since we have no interest on email body and other emails that mismatch the query, we need the options --body=false and --entire-thread=false. As stated above, we also want S-expression as output format, e.g. --format=sexp. Putting together:\n1  notmuch show --body=false --entire-thread=false --format=sexp \u0026lt;search-term\u0026gt;   where search-term corresponds, in notmuch jargon, to the query expression.\nFrom notmuch show documentation, a thread corresponds to a nested structure. For testing purpose, I wrote to myself several emails to obtain two threads of the following structure (with the sent time to better identifying them later):\n1 2 3 4 5 6 7 8 9 10 11  |- email 1 (12:32:37) | | | |-- email 2 (12:32:56) | | | | | |- email 3 (12:33:18) | | | |-- email 4 (12:33:34) | |- email 5 (12:44:34) | |- email 6 (12:45:41)   \u0026hellip; and use an appropriate search term to filter out exactly these threads.\nThe notmuch package already provides the function notmuch-call-notmuch-sexp to convert the shell output to Emacs Lisp S-expression.1 We can thus translate the previous shell command into\n1 2  (notmuch-call-notmuch-sexp \u0026#34;show\u0026#34; \u0026#34;--body=false\u0026#34; \u0026#34;--entire-thread=false\u0026#34; \u0026#34;--format=sexp\u0026#34; search-term)   But! My instinct tells me that we could have better. So, searching which functions actually call notmuch-call-notmuch-sexp brings me to the library notmuch-query which contains lots of useful functions. In particular, the function call above can, kind of2, be simplify to\n1  (notmuch-query-get-threads (list search-term))   Notmuch thread structure In notmuch, an email corresponds to a property list (plist) with the following fields id, match, excluded, filename, timestamp, date_relative, tags, body, crypto, headers. Needless to say, we will pay particular attention on headers. tags and body could be useful for further development. The command above returns me six plists surrounded by countless parentheses. To understand better the structure, I replaced the plists by the sent time:\n1 2 3 4 5 6 7  (((\u0026#34;12:44:34\u0026#34; ((\u0026#34;12:45:41\u0026#34; nil)))) ((\u0026#34;12:32:37\u0026#34; ((\u0026#34;12:32:56\u0026#34; ((\u0026#34;12:33:18\u0026#34; nil))) (\u0026#34;12:33:34\u0026#34; nil)))))   Comparing to the threads I artificially created, it\u0026rsquo;s pretty much the same.\nFlatten the S-expression The tree structure is not relevant for our purpose, so we want to flatten it as a list of plist. We actually don\u0026rsquo;t want to parse the S-expression ourselves, as stated above, the notmuch-query library provides some functions we can use directly. It can be done by\n1 2  (notmuch-query-map-threads #\u0026#39;identity (notmuch-query-get-threads (list search-term)))   And as it is actually a map function, to obtain a list of headers we can simply define the following function.\n1 2 3 4  (defun notmuch-notify--show-headers (search-term) (notmuch-query-map-threads (lambda (p) (plist-get p :headers)) (notmuch-query-get-threads (list search-term))))   Conclusion Having emails header given a search term, we can now easily introduce subject and email sender along with the notification message.\nSee my work-in-progress package notmuch-notify for more information!\n Equivalently, one can use (read (shell-command-to-string ...)) for the same purpose. But notmuch-call-notmuch-sexp is more robust as it offers error handling. \u0026#x21a9;\u0026#xfe0e;\n It misses the arguments --body=false and --entire-thread=false, but they are actually not so important as they won\u0026rsquo;t save us much performance. \u0026#x21a9;\u0026#xfe0e;\n   ","description":"","id":1,"section":"posts","tags":["notmuch","email","emacs-lisp","emacs"],"title":"Obtain emails header in notmuch","uri":"https://firminmartin.com/en/posts/2021/03/obtain_emails_header_in_notmuch/"},{"content":"Introduction From time to time, I want to search over my dotfiles, precisely those immediately under my home directory ~/. The problem of grep -R \u0026lt;regex\u0026gt; is that it quickly delves into an oceanic trench, full of caches, xml files or databases. In other words, it uses a depth-first approach.\nbfs-grep The following shell function helps me greatly to deal with such a situation. It employs a breadth-first search, i.e. level by level. It is written for zsh but should work for bash or ksh931. The tput commands are just used to redden the level announcement. Further tweaks can be made such as changing the dot . (current directory) to a target directory or starting from a specific level. But that\u0026rsquo;s enough for me.\n1 2 3 4 5 6  function bfs-grep { for i in $(seq 1 $1); do \u0026gt;\u0026amp;2 echo \u0026#34;$(tput setaf 1)BFS-GREP: LEVEL $i$(tput sgr0)\u0026#34; find . -mindepth $i -maxdepth $i -type f -exec grep \u0026#34;${@:2}\u0026#34; {} +; done }   Usage bfs-grep first argument is the maximum depth to search, starting from 1 for the current level. The remaining arguments are fed to grep.\n See here for ${@:2}. \u0026#x21a9;\u0026#xfe0e;\n   ","description":"","id":2,"section":"posts","tags":["cli","shell","linux"],"title":"Breadth-first search grep","uri":"https://firminmartin.com/en/posts/2021/03/bfs-grep/"},{"content":"Few days ago, I bought a USB Wi-Fi adapter to learn about pentesting. The goal was using this adapter to connect a virtual Kali Linux distribution in VirtualBox to Wi-Fi network through USB.\nAfter some hesitations, I picked up a cheap enough model which uses a RT18812AU chip. An important factor to choose this chip is that it is dual-band. This was the first time I\u0026rsquo;m dealing with such material. Of course, there was no such thing as plug-and-play. So I had to manually install the driver.\n\n  Figure 1: The Wi-Fi adapter I bought.\n  The adapter comes with a \u0026ldquo;quick installation guide\u0026rdquo; written in gibberish English.1 So, not very promising. I decided to insert directly the provided CD and see if I can do something. There were three directories for respectively OSX, Windows and Linux. I extracted the Linux directory and ran the install.sh without too much hesitation. It failed. No worry, such thing happens, I read the install.sh, again gibberish English comments2\u0026hellip; I went to the driver directory (rtl88x2BU_WiFi_linux_v5.3.1_27678.20180430_COEX20180427-5959) to see if I can do something and got the marvelous idea to feed the driver name to Google to see if I can get an up-to-date version. I found one,\n1  git clone https://github.com/morrownr/88x2bu.git   and followed the instructions. It compiles! The bad news is the plugged adapter doesn\u0026rsquo;t have any sign of life. Weird! After all kinds of attempts and reboots, I naively ran a new command\n1  lsusb   which reveals that the chip was actually a RT18812AU. I double-checked the chip model and realized that it\u0026rsquo;s right, and thought I bought a BU but finally picked a AU. So\u0026hellip; why they ever put an outdate RT18812BU in the CD? Mystery. Again, I searched a driver for this chip, and found this one:\n1  git clone https://github.com/gnab/rtl8812au   \u0026hellip; followed the instructions, and bingo! The adapter LED started blinking. I expected that it would work painless in VirtualBox\u0026hellip; was wrong. In the Kali Linux USB settings, the button \u0026ldquo;add new USB filter\u0026rdquo; didn\u0026rsquo;t display my USB devices, contrary to what I expected. After heavy surfing on the Internet, I found this relevant thread. Ah, I wasn\u0026rsquo;t in vboxusers group:\n1  groups   So, I had to add it.\n1  sudo usermod -a -G vboxusers firmart   Logged out. Log back. And finally:\n\n  Figure 2: The Wi-fi adapter detected on VirtualBox.\n  Ventre Saint-Antoine!, would say a medieval Frenchman.\nConclusion.\n If you are on Linux, do not even bother to insert the CD (and to read the \u0026ldquo;quick installation guide\u0026rdquo;). Search right away on Google \u0026lt;chip\u0026gt; github and you would find an enhanced driver with a useful README. lsusb is actually useful to make sure the USB device is there and to double-check the chip model.  This tale3 would not be written without the help of ~/.zsh_history and my browser history.\n It starts with a typo: \u0026ldquo;Chater 1: driver installation\u0026rdquo;. \u0026#x21a9;\u0026#xfe0e;\n \u0026ldquo;Novembor\u0026rdquo;; \u0026ldquo;Drvfoulder\u0026rdquo; for driver folder. \u0026#x21a9;\u0026#xfe0e;\n Dated of 2021-02-22. \u0026#x21a9;\u0026#xfe0e;\n   ","description":"","id":3,"section":"posts","tags":["hardware","driver","virtualbox"],"title":"A tale of installing RT18812AU driver and make it works in VirtualBox","uri":"https://firminmartin.com/en/posts/2021/03/a_tale_of_installing_rt18812au_driver_and_make_it_works_in_virtualbox/"},{"content":"Background I was looking for a way to classifying images by rating them on the fly. My first attempt was using darktable as suggested in a thread. Indeed, the auto-advance rating mechanism was quite handy. But it is still too heavy for this sole purpose. In darktable, user have to import images before editing metadata. When tens of thousands images are involved, the process of importing images can be quite time-consuming1 as it creates for each image an XMP file to store metadata. And this also applies to rating, even though I configure it to improve performance (without OpenCL) the latency is counted by seconds. Moreover, XMP are also created for symlink of image. This was not plausible in my use-case2 as it enforces me to keep multiple metadata files for the same image.\nLots of critics, but clearly darktable was not the right tool. It suits better on raw photo post-production as intended. I will present in this post two solutions to remediate the issues aforementioned.\nGoals After experiencing darktable, I know better what I am seeking:\n Edit metadata in the image file itself. This has two advantages:  Keep metadata even if the filename is changed. Get rid of XMP files.   Preview and select image without latency. Namely, preview images and rate them on the fly. Metadata editing should follow symlink. To centralize metadata in the same place. Batch rating. Rating a whole directory or multiple selected images at once.  Exiftool ExifTool is a free and open-source software program for reading, writing, and manipulating image, audio, video, and PDF metadata.\nRating images with exiftool Rating image with exiftool is very simple.\n1  exiftool -rating=5 -overwrite_original_in_place \u0026lt;files\u0026gt;   The option -overwrite_original_in_place overwrite directly the file(s) instead of moving the original one to filename.ext_original. Use it wisely at your own risk.\nTo read back the rating:\n1  exiftool -rating \u0026lt;files\u0026gt;   \u0026hellip; or format yourself the output:\n1  exiftool -p \u0026#39;$Rating $Filepath\u0026#39; -f \u0026lt;files\u0026gt;   And, of course the symbolic links are followed3!\nBut with exiftool alone, one cannot watch and rate image at the same time. This can be done by combine up exiftool with a file manager having preview ability or an image viewer. Next, I will show how to integrate exiftool capability in the file manager ranger and the image viewer sxiv.\nFile types supported by exiftool In fact, the version 11.88 of exiftool already supports a large set of file types. Thus, what has been and will be said is not limited to images and rating.\nTable 1: File types supported by exiftool (v11.88) (r = read, w = write, c = create).              3FR (r) DR4 (r/w/c) ITC (r) ODP (r) RIFF (r)   3G2 (r/w) DSS (r) J2C (r) ODS (r) RSRC (r)   3GP (r/w) DV (r) JNG (r/w) ODT (r) RTF (r)   A (r) DVB (r/w) JP2 (r/w) OFR (r) RW2 (r/w)   AA (r) DVR-MS (r) JPEG (r/w) OGG (r) RWL (r/w)   AAE (r) DYLIB (r) JSON (r) OGV (r) RWZ (r)   AAX (r/w) EIP (r) K25 (r) OPUS (r) RM (r)   ACR (r) EPS (r/w) KDC (r) ORF (r/w) SEQ (r)   AFM (r) EPUB (r) KEY (r) OTF (r) SKETCH (r)   AI (r/w) ERF (r/w) LA (r) PAC (r) SO (r)   AIFF (r) EXE (r) LFP (r) PAGES (r) SR2 (r/w)   APE (r) EXIF (r/w/c) LNK (r) PBM (r/w) SRF (r)   ARQ (r/w) EXR (r) LRV (r/w) PCD (r) SRW (r/w)   ARW (r/w) EXV (r/w/c) M2TS (r) PCX (r) SVG (r)   ASF (r) F4A, F4V (r/w) M4A, M4V (r/w) PDB (r) SWF (r)   AVI (r) FFF (r/w) MAX (r) PDF (r/w) THM (r/w)   AVIF (r/w) FITS (r) MEF (r/w) PEF (r/w) TIFF (r/w)   AZW (r) FLA (r) MIE (r/w/c) PFA (r) TORRENT (r)   BMP (r) FLAC (r) MIFF (r) PFB (r) TTC (r)   BPG (r) FLIF (r/w) MKA (r) PFM (r) TTF (r)   BTF (r) FLV (r) MKS (r) PGF (r) TXT (r)   CHM (r) FPF (r) MKV (r) PGM (r/w) VCF (r)   COS (r) FPX (r) MNG (r/w) PLIST (r) VRD (r/w/c)   CR2 (r/w) GIF (r/w) MOBI (r) PICT (r) VSD (r)   CR3 (r/w) GPR (r/w) MODD (r) PMP (r) WAV (r)   CRM (r/w) GZ (r) MOI (r) PNG (r/w) WDP (r/w)   CRW (r/w) HDP (r/w) MOS (r/w) PPM (r/w) WEBP (r)   CS1 (r/w) HDR (r) MOV (r/w) PPT (r) WEBM (r)   CSV (r) HEIC (r/w) MP3 (r)4 PPTX (r) WMA (r)   DCM (r) HEIF (r/w) MP4 (r/w) PS (r/w) WMV (r)   DCP (r/w) HTML (r) MPC (r) PSB (r/w) WTV (r)   DCR (r) ICC (r/w/c) MPG (r) PSD (r/w) WV (r)   DFONT (r) ICS (r) MPO (r/w) PSP (r) X3F (r/w)   DIVX (r) IDML (r) MQV (r/w) QTIF (r/w) XCF (r)   DJVU (r) IIQ (r/w) MRW (r/w) R3D (r) XLS (r)   DLL (r) IND (r/w) MXF (r) RA (r) XLSX (r)   DNG (r/w) INSP (r/w) NEF (r/w) RAF (r/w) XMP (r/w/c)   DOC (r) INSV (r) NRW (r/w) RAM (r) ZIP (r)   DOCX (r) INX (r) NUMBERS (r) RAR (r)    DPX (r) ISO (r) O (r) RAW (r/w)     ranger ranger is a free and open-source CLI files manager I\u0026rsquo;m using for years. It is very handy to select images and preview them5.\nAppend the following snippet in ~/.config/ranger/commands.py. It will add the custom command rate_image \u0026lt;0-5\u0026gt; \u0026lt;files\u0026gt;.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36  # ~/.config/ranger/commands.py class rate_image(Command): \u0026#34;\u0026#34;\u0026#34;:rate_image \u0026lt;0-5\u0026gt; \u0026lt;files\u0026gt; Command for rating image with exiftools. \u0026#34;\u0026#34;\u0026#34; def execute(self): import subprocess if self.arg(1): rating_score = self.arg(1) else: self.fm.notify(\u0026#34;rate_image: a rating score is required!\u0026#34;, bad=True) return if self.arg(2): files = self.arg(2) else: cwd = self.fm.thisdir cf = self.fm.thisfile if not cwd or not cf: self.fm.notify(\u0026#34;Error: no file selected for deletion!\u0026#34;, bad=True) return if len(cwd.marked_items) \u0026gt; 1: files = \u0026#34; \u0026#34;.join([f.shell_escaped_basename for f in cwd.marked_items]) self.fm.mark_files(all=True, val=False) else: files = cf.shell_escaped_basename command = \u0026#34;exiftool -rating=\u0026#34; + rating_score + \\ \u0026#34; -overwrite_original_in_place \u0026#34; + files self.fm.notify(\u0026#34;Run command: \u0026#34; + command) result = self.fm.execute_command(command, stdout=subprocess.PIPE) stdout, stderr = result.communicate() if result.returncode == 0: # This is a generic function to print text in ranger. self.fm.notify(\u0026#34;Succeeded to rate image \u0026#34; + files + \\ \u0026#34; with score \u0026#34; + rating_score + \u0026#34;.\u0026#34;)   It remains to define some key bindings to be granted the full power of ranger. Append the following snippet to ~/.config/ranger/rc.conf.\n1 2 3 4 5 6  # ~/.config/ranger/rc.conf map r1 rate_image 1 map r2 rate_image 2 map r3 rate_image 3 map r4 rate_image 4 map r5 rate_image 5   The resulting workflow is as follows:\n Select images with SPC (single selection) or v (reverse selection). Press r and the rating 1 to 5.    sxiv sxiv is a free, open-source, lightweight and scriptable image viewer. Add the following entries in ~/.config/sxiv/exec/key-handler6\n1 2 3 4 5 6 7 8 9  # ~/.config/sxiv/exec/key-handler case \u0026#34;$1\u0026#34; in # ... \u0026#34;C-1\u0026#34;) tr \u0026#39;\\n\u0026#39; \u0026#39;\\0\u0026#39; | xargs -0 -I {} exiftool -rating=1 -overwrite_original_in_place \u0026#34;{}\u0026#34; ;; \u0026#34;C-2\u0026#34;) tr \u0026#39;\\n\u0026#39; \u0026#39;\\0\u0026#39; | xargs -0 -I {} exiftool -rating=2 -overwrite_original_in_place \u0026#34;{}\u0026#34; ;; \u0026#34;C-3\u0026#34;) tr \u0026#39;\\n\u0026#39; \u0026#39;\\0\u0026#39; | xargs -0 -I {} exiftool -rating=3 -overwrite_original_in_place \u0026#34;{}\u0026#34; ;; \u0026#34;C-4\u0026#34;) tr \u0026#39;\\n\u0026#39; \u0026#39;\\0\u0026#39; | xargs -0 -I {} exiftool -rating=4 -overwrite_original_in_place \u0026#34;{}\u0026#34; ;; \u0026#34;C-5\u0026#34;) tr \u0026#39;\\n\u0026#39; \u0026#39;\\0\u0026#39; | xargs -0 -I {} exiftool -rating=5 -overwrite_original_in_place \u0026#34;{}\u0026#34; ;; esac   The resulting workflow is as follows:\n Open images with sxiv. Press C-x C-\u0026lt;1..5\u0026gt; to rate the current image. Or mark images with m7, toggle thumbnails mode with RET and press C-x C-\u0026lt;1..5\u0026gt; to rate selected images.  Bonus Some interesting tips are presented here. The main dependencies are zsh and GNU parallel, adapt it to fit your need.\nRate or view images of specific rating The long command below search all JPG files (potentially symlink) of rating 3, 4 or 5 and view them with sxiv.\n1 2 3 4 5 6 7 8 9 10 11 12 13  # 1. Find recursively all JPG under the current directory # 2. Use GNU parallel, for each JPG # (a) noglob (zsh specific): disable zsh globing to prevent \u0026#34;No such file\u0026#34; error # (b) Build the string \u0026#34;$Rating $Filepath\u0026#34; # (c) Remove the last line of exiftool output which count the amounts of the files. # (d) Keep entry with $Rating in {3, 4, 5}. Remove the first space. # 3. Use GNU parallel: view at most 250 found images with sxiv at a time. find -L . -type f -regex \u0026#34;.*\\.jpg\u0026#34; | parallel -L 5000 \\  \u0026#39;noglob exiftool -p \u0026#39;\\\u0026#39;\u0026#39;$Rating $Filepath\u0026#39;\\\u0026#39;\u0026#39; -f -q -q {} | \\ head --lines=-1 | \\ awk \u0026#39;\\\u0026#39;\u0026#39;$1 ~ /[345]/ {$1=\u0026#34;\u0026#34;; print substr($0, 2)}\u0026#39;\\\u0026#39;\u0026#39; \u0026#39; | parallel -L 250 -q sxiv \u0026#34;{}\u0026#34;   Some remarks:\n To see unrated images, use - as rating, then you can rate them with sxiv as above. This one-shot command is fast enough for hundreds of images. Above this amount, you may want to take some time to dump the result in a file as follows.   1 2 3 4 5  find -L -type f -regex \u0026#34;.*\\.jpg$\u0026#34; | parallel -L 5000 \\  \u0026#39;noglob exiftool -p \u0026#39;\\\u0026#39;\u0026#39;$Rating $Filename\u0026#39;\\\u0026#39;\u0026#39; -f -q -q {} | \\ head --lines=-1 | \\ awk \u0026#39;\\\u0026#39;\u0026#39;$1 ~ /[^0-]/ {print $0}\u0026#39;\\\u0026#39;\u0026#39; \u0026#39; \u0026gt;\u0026gt; ratingdb.txt   And view images with specific rating with this command:\n1 2  awk \u0026#39;$1 ~ /345/ {$1=\u0026#34;\u0026#34;; print substr($0, 2)}\u0026#39; ratingdb.txt | parallel -L 250 -q sxiv \u0026#34;{}\u0026#34;    The best would be writing a python script to maintain an SQLite database, and adapt the script of ranger and sxiv above to update the database each time a file rating changed. shuf may be used after awk to shuffle images before viewing them. Actually, no one will type again and again those lengthy commands. I either use C-R in zsh with fzf for casual ones or add them as entries in pet, a manager of parametrizable snippet.  Migrate XMP rating into image metadata If you migrate from darktable or have XMP files with rating, you can try the following commands.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  zmodload zsh/mapfile # 1. Find recursively all XMP under the current directory # 2. Use GNU parallel, for each XMP # (a) Extract the rating with grep and awk; put it in $RATE. # (b) Append the image path to .xmp-$RATE-rating.db find . -type f -regex \u0026#34;.*\\.xmp\u0026#34; -print0 | parallel -0 \u0026#39;TMP=$(grep -o \u0026#34;Rating=\\\u0026#34;[012345]\\\u0026#34;\u0026#34; {} | \\ awk \u0026#39;\\\u0026#39;\u0026#39;{print gensub(/Rating=\u0026#34;([0-5])\u0026#34;/, \u0026#34;\\1\u0026#34;, \u0026#34;g\u0026#34;, $1)}\u0026#39;\\\u0026#39;\u0026#39;); \\ echo {} \u0026gt;\u0026gt; xmp-$TMP-rating.db\u0026#39; # 3. For each $RATE: for i in {1..5}; do FNAME=\u0026#34;xmp-$i-rating.db\u0026#34; # For each file in .xmp-$RATE-rating.db for f in \u0026#34;${(f)mapfile[$FNAME]}\u0026#34;; do # Use exiftool to rate it with the corresponding $RATE exiftool -rating=$i -overwrite_original_in_place \u0026#34;${f%.*}\u0026#34; done done    Dozen hours for 950.000 images. \u0026#x21a9;\u0026#xfe0e;\n Statistical classification of images. For each class, it creates a directory in which each symbolic link is associated to the actual image. \u0026#x21a9;\u0026#xfe0e;\n Beware, without -overwrite_original_in_place, symlink will be removed! \u0026#x21a9;\u0026#xfe0e;\n You may notice that you can\u0026rsquo;t write MP3 metadata. ffmpeg should be used instead. \u0026#x21a9;\u0026#xfe0e;\n As long as you use the right terminal emulator, e.g. iTerm, kitty, urxvt, xterm etc. From my past experience, Elementary OS\u0026rsquo;s pantheon-terminal doesn\u0026rsquo;t work. \u0026#x21a9;\u0026#xfe0e;\n If this file doesn\u0026rsquo;t exist, you can copy the sample one: mkdir -p ~/.config/sxiv/exec/ \u0026amp;\u0026amp; cp /usr/share/doc/sxiv/examples/key-handler . \u0026#x21a9;\u0026#xfe0e;\n See sxiv/config.def.h for more keybindings to mark images. \u0026#x21a9;\u0026#xfe0e;\n   ","description":"","id":4,"section":"posts","tags":["linux","ranger","exiftool","zsh"],"title":"Rating images painlessly with exiftool feat. ranger \u0026 sxiv","uri":"https://firminmartin.com/en/posts/2020/12/rating_images_painlessly_with_exiftool/"},{"content":"It has been 18 months that I read \u0026amp; write my emails in Emacs. No need to say I have enjoyed the mouse-free experience brought by Emacs. Recently, I had to keep track a new email account. So I came across my old note written back then which I enhanced in this post. I made lots of updates subsequently including password management through pass, multi-accounts support etc. to make it as complete as possible.\nIntroduction A full back-and-forth cycle of email consists to\n Receive email through a program which synchronize emails locally from an email server. Read email through a program (MUA) whose the UI offers an organized \u0026amp; handy presentation of emails. Compose email in whatever editor. Send email with a mail transfer agent or an interface of it.  I made the following choices which I will detail the configuration throughout this post:\n Receive email: offlineimap. Read email: notmuch.el. Compose email: Emacs message mode. Send email: smtpmail-multi to send email through multiple SMTP servers.  As you may have seen, except the reception of email, the remaining can be done within Emacs.\nReceiving email As stated above, we use offlineimap to fetch emails from potentially multiple mailbox. But most importantly, we store all emails locally for two purposes: 1. to be able to read emails offline, 2. to not mess up tags synchronization which may cause data loss. You may think that your huge mailbox would take a tremendous place in your disk. Well, I can say that if you pay attention to keep only one copy of your emails1, it should not take much. For instance, I have 2.6k emails taking 460MB of the disk.\nConfigure offlineimap Install offlineimap with your favorite package manager2. Then copy the minimal configuration (the path depends on your distribution).\n1  cp /usr/share/doc/offlineimap/examples/offlineimap.conf.minimal ~/.offlineimaprc   Here is the relevant part of my configuration (~/.offlineimaprc) for reference. See the documentation in /usr/share/doc/offlineimap/examples/offlineimap.conf or Archwiki for more information. Note the postsynchook option at the account level: it\u0026rsquo;s an email tagging script which is run as soon as new email arrives. We will come soon to its content in this section. Remember what I said regarding the space taken by locally stored email? Well, they remain tiny provided that they are not duplicated elsewhere. That\u0026rsquo;s not always the case, for instance Gmail may store an email in the folder [Gmail].Important beside [Gmail].All Mail. You may consider to filter out the extra folders you don\u0026rsquo;t want as below with a python\u0026rsquo;s lambda expression or a function (see the documentation).\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24  # ~/.offlineimaprc [general] accounts = Acc1_Gmail, Acc2, Acc3 # comma-separated list of accounts [Account Acc1_Gmail] localrepository = LocalAcc1 remoterepository = RemoteAcc1 postsynchook = ~/.email/postsync.sh # notmuch tagging script utf8foldernames = yes [Repository LocalAcc1] type = Maildir localfolders = ~/.email/my-acc1@gmail.com [Repository RemoteAcc1] type = Gmail remoteuser = my-acc1@gmail.com remotepass = password sslcacertfile = /etc/ssl/certs/ca-certificates.crt readonly = true # readonly if you don\u0026#39;t want mess up with the \u0026#39;unread\u0026#39; tag... folderfilter = lambda foldername: foldername in [\u0026#39;[Gmail].All Mail\u0026#39;] [Account Acc2] ... ...   Launch offlineimap automatically at boot You would certainly want to launch automatically offlineimap at boot. This can be done with systemd. In my case, I have three accounts, it\u0026rsquo;s advised 3 to create three separated systemd services and set maxsyncaccounts = 1 in ~/.offlineimaprc as we have done above.\nInstead of write three different system service files, I write the following template unit file where the variable %i will match later with an account name in .offlineimaprc. (Note that you should avoid \u0026ldquo;@\u0026rdquo; in the account name since systemd gives it a precise meaning).\n1 2 3 4 5 6 7 8 9 10 11 12  # ~/.config/systemd/user/offlineimap@.service [Unit] Description=Sync mail with offlineIMAP for Account %i in .offlineimaprc Documentation=man:offlineimap(1) [Service] ExecStart=/usr/bin/offlineimap -a %i -u basic Restart=always RestartSec=60 [Install] WantedBy=default.target   Then run systemctl daemon-reload to load the new service file. The following commands enable the auto-start on boot and launch the service right now.\n1 2 3  systemctl enable --user --now offlineimap@account-1.service systemctl enable --user --now offlineimap@account-2.service systemctl enable --user --now offlineimap@account-3.service   Note that account-* is the account name appeared in each [ Account XXX ] section. If everything goes well, offlineimap will sync emails on the next boot automatically.\nAuto-tagging with notmuch The next thing to do is email auto-tagging, without this feature your mailbox will be a nightmare. Again, install notmuch with your favorite package manager. We will write the script aforementioned so that email be filtered as soon as they are synced locally.\nConfigurate notmuch Before starting to use notmuch, you must configure it. In particular, you have to set the database path, your email accounts which appeared in ~/.offlineimaprc, tagging rule for incoming email and tag to exclude by default when searching.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  # ~/.notmuch-config [database] path=/home/firmart/.email [user] name=Firmin Martin primary_email=my-acc1@gmail.com other_email=my-acc2@gmail.com; my-acc3@gmail.com [new] tags=inbox;unread; ignore= [search] exclude_tags=deleted; [maildir] synchronize_flags=true   Expose highly active addresses The following command lists email-senders address sorted by decreasing amounts of emails sent4.\n1 2 3  notmuch show --format=json --body=false --entire-thread=false \u0026#34;*\u0026#34; | jq \u0026#39;.[] | .[] | .[0].headers.From\u0026#39; | sort | uniq -c | sort -n   Replace From by To to expose highly active mailing list.\nThe snippet above help us to find out the best contributors of our inbox to tag them properly.\nAuto-tagging script Here is my little shell script ~/.email/postsync.sh which is run once offlineimap finished to sync my emails. You might want to take a look at notmuch help search-terms to understand the syntax of tagging commands.\nI identify several visibility categories of emails:\n I don\u0026rsquo;t want to see them at all and they\u0026rsquo;re harmful =\u0026gt; spam I don\u0026rsquo;t want to see them at all =\u0026gt; blacklisted I want to see them but it doesn\u0026rsquo;t matter when =\u0026gt; move out inbox It\u0026rsquo;s important! =\u0026gt; keep them in the inbox and tag them more   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59  #!/usr/bin/env bash # ~/.email/postsync.sh # tag_new \u0026lt;tags\u0026gt; \u0026lt;search-term\u0026gt; function tag_new { notmuch tag $1 -- tag:inbox and $2; } # blacklist \u0026lt;search-term\u0026gt; function blacklist { tag_new \u0026#34;-inbox -unread +deleted\u0026#34; $1; } # spam \u0026lt;search-term\u0026gt; function spam { tag_new \u0026#34;-inbox -unread +spam +deleted\u0026#34; $1; } # security \u0026lt;search-term\u0026gt; function security { tag_new \u0026#34;-inbox +Security\u0026#34; $1; } # update : let notmuch process new mails notmuch new # blacklisting notmuch tag -inbox -- tag:deleted and tag:inbox blacklist \u0026#34;from:/.*@.*[.]pinterest[.]com/\u0026#34; blacklist \u0026#34;from:/.*@linkedin[.]com/\u0026#34; blacklist \u0026#34;from:/.*@quora[.]com/\u0026#34; blacklist \u0026#34;from:noreply@medium.com\u0026#34; blacklist \u0026#34;from:noreply@youtube.com\u0026#34; ## this list continue with 100+ addresses ... # ... and spams # `+spam\u0026#39; can\u0026#39;t be found at all in notmuch if `exclude_tags=deleted;spam;\u0026#39; # is set in the [search] section of `.notmuch-config\u0026#39;. spam \u0026#34;from:esf@cnnsimail.com\u0026#34; # ... # Family first tag_new \u0026#34;+family\u0026#34; \u0026#34;from:dad@gmail.com or from:mom@gmail.com\u0026#34; # Friends # ... # Co-workers # ... # Mailing list tag_new \u0026#34;-inbox +CoqClub\u0026#34; \u0026#34;to:coq-club@inria.fr or [Coq-Club]\u0026#34; # Newsletter tag_new \u0026#34;-inbox +SE.newsletter\u0026#34; \u0026#34;from:do-not-reply@stackoverflow.email\u0026#34; # Universities # ... # Security (accounts/verification code/email confirmation/... etc.) security \u0026#34;from:no-reply@accounts.google.com or accounts-noreply@google.com\u0026#34; security \u0026#34;from:account-security-noreply@account.microsoft.com\u0026#34; # and more ... # From me tag_new \u0026#34;-inbox -unread +FromMe\u0026#34; \u0026#34;from:my-main-gmail@gmail.com or from:univ-account@my-univ.fr or from:my-second@gmail.com\u0026#34;   Reading mail notmuch.el Follow the instructions given on the official website.\nKey-bindings The key-bindings I use are from evil-collection. They are quite different from the default ones. You can define new keybindings for different notmuch views (tree, show, hello, search, message) as below, but usually I rarely tag manually an email (except flagging important one). Instead, I add a new tagging rule as depicted above.\n1 2 3 4 5  (define-key notmuch-show-mode-map \u0026#34;S\u0026#34; (lambda () \u0026#34;delete message and move on\u0026#34; (notmuch-show-tag \u0026#39;(\u0026#34;+deleted\u0026#34; \u0026#34;-unread\u0026#34;)) (notmuch-show-next-open-message-or-pop)))   Compose email Simply press C-x m (compose-mail) in Emacs to compose an email to send. Normally, the From:=/=To: fields can be autocompleted.\nSend email Unless your local system is configured for sending email using sendmail, you may want to access a remote SMTP server.\nSMTP configuration Below is a fragment of my SMTP setup. You should acquire this information from the host (Gmail5, your institution, your company etc.). Using smtpmail is not enough to sending email with different accounts. Fortunately, the package smtpmail-multi made the task easier.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  (use-package smtpmail-multi :ensure t :config (setq smtpmail-multi-accounts \u0026#39;((host . (\u0026#34;firmin.martin@host.fr\u0026#34; \u0026#34;smtp.host.fr\u0026#34; 587 \u0026#34;firmin.martin@host.fr\u0026#34; nil nil nil nil)) (gmail-main . (\u0026#34;firmin.martin@gmail.com\u0026#34; \u0026#34;smtp.gmail.com\u0026#34; 587 \u0026#34;firmin.martin@gmail.com\u0026#34; nil nil nil nil)))) (setq smtpmail-multi-associations \u0026#39;((\u0026#34;firmin.martin@host.fr\u0026#34; host) (\u0026#34;firmin.martin@gmail.com\u0026#34; gmail-main))) (setq smtpmail-multi-default-account \u0026#39;gmail-main) (setq message-send-mail-function \u0026#39;smtpmail-multi-send-it) (setq smtpmail-debug-info t) (setq smtpmail-debug-verbose t))   Then you have to put your credentials somewhere. Such places are designated by the variable auth-sources which defaults to (\u0026quot;~/.authinfo\u0026quot; \u0026quot;~/.authinfo.gpg\u0026quot; \u0026quot;~/.netrc\u0026quot;).\nFor instance, put the following in ~/.authinfo.\n1 2  machine smtp.host.fr login firmin.martin port 587 password abc123 machine smtp.gmail.com login firmin.martin port 587 password abc123   Patch: Fully-Qualified Domain Name (FQDN) You may encounter issue regarding the FQDN when sending email. I have the following patch in my configuration coming from here.\n1 2  (when (\u0026gt;= emacs-major-version 25) (setq smtpmail-local-domain (car (split-string (shell-command-to-string \u0026#34;hostname -f\u0026#34;)))))   Bonus: passwords encryption with pass You may have seen a security hole which would hopefully make you uncomfortable: we have written credentials in plain text. Let\u0026rsquo;s fix it. I assume in the following that the reader has already setup gpg (2.1+) and pass.\nRemember, we have stored passwords in ~/.offlineimaprc to pull emails locally with offlineimap and in ~/.authinfo so that Emacs is able to send email.\n~/.offlineimaprc Quoting ArchWiki:\n  Create a password for your email account.\n1  pass insert email/myaccount     Create a python function that retrieves the password (in ~/.offlineimap/pass.py for instance).\n1 2 3 4 5  #! /usr/bin/env python3 from subprocess import check_output def get_pass(account): return check_output(\u0026#34;pass email/\u0026#34; + account, shell=True).splitlines()[0]     In .offlineimaprc, under the general section, indicate the python file\n1 2 3  [general] # ... pythonfile = ~/.offlineimap/pass.py   and replace each remotepass = password by the next one.\n1  remotepasseval = get_pass(\u0026#34;myaccount\u0026#34;)     auth-source-pass To make Emacs read credentials through pass, we use the package auth-source-pass which exactly do the job for us. The configuration is simple.\n1 2 3 4  (use-package auth-source-pass :ensure t :config (auth-source-pass-enable))   You should create a \u0026lt;smtp host\u0026gt;.gpg with pass --edit email/\u0026lt;smtp host\u0026gt; for each smtp server. For instance, the entry of .authinfo\n1  machine smtp.host.fr login firmin.martin port 587 password abc123   corresponds to ~/.password-store/email/smtp.host.fr.gpg\n1 2 3 4  abc123 user: firmin.martin host: smtp.host.fr port: 587   Cache gpg passphrase By now, offlineimap and Emacs will retrieve your passwords through pass. Great! But, if you setup gpg without extra configuration, you will be prompted the passphrase every two hours. Why? The answer lies in the gpg agent options default-cache-ttl and --max-cache-ttl. The documentation says\n1 2 3 4 5 6 7 8 9 10 11 12  --default-cache-ttl n Set the time a cache entry is valid to n seconds. The default is 600 seconds. Each time a cache entry is accessed, the entry’s timer is reset. To set an entry’s maximum lifetime, use max-cache-ttl. Note that a cached passphrase may not be evicted immediately from memory if no client requests a cache operation. This is due to an internal housekeeping function which is only run every few seconds. --max-cache-ttl n Set the maximum time a cache entry is valid to n seconds. After this time a cache entry will be expired even if it has been accessed recently or has been set using gpg-preset-passphrase. The default is 2 hours (7200 seconds).   That is, by default, the passphrase is cached 10 minutes and can be extended each time it is accessed up to 2 hours. As we set RestartSec=60 in ~/.config/systemd/user/offlineimap@.service, it ensures that we reach the maximum cache time. To increase the cache time permanently to one day, add the line below in ~/.gnupg/gpg-agent.conf.6\n1  max-cache-ttl 86400   You should restart gpg-agent to see the effect (gpg -K should be enough). At this point, not only are your passwords secure to some extent, but no one can see and write emails on your behalf after one day without enter the passphrase.\nAddendum: general workflow I summarize below how one maintains this email workflow.\n  Tagging emails. Update ~/.email/postsync.sh when necessary (usually to blacklist some addresses).\n  Changing password. Modify adequately ~/.offlineimaprc and .authinfo, or if you use pass as above, update the passwords with pass edit email/\u0026lt;account\u0026gt;. Beware, if you only change your password remotely, you won\u0026rsquo;t be able to receive and (possibly) write any email.\n  Adding new email. Each time you want to add a new email account in you workflow, you should\n update .offlineimaprc: update accounts, add one more account section plus  associated local/remote sections;\n update .notmuch-config: update primary_email or other_email; update smtpmail-multi-accounts and smtpmail-multi-associations if that account may be used to write email; update credentials with pass; run systemctl enable --user --now offlineimap@ACCOUNT-NAME.service; (optional) update postsync.sh to tag the email written by yourself.     After setting up offlineimap correctly, you can check this information by running fdupes -mr . under ~/.email/. \u0026#x21a9;\u0026#xfe0e;\n Note that, at the time of writing, offlineimap is in the process to port from python2 (2020-01-01 ⚰️) to python3, see OfflineIMAP/offlineimap3. \u0026#x21a9;\u0026#xfe0e;\n OfflineIMAP community\u0026rsquo;s website : No, I\u0026rsquo;m not using maxconnections \u0026#x21a9;\u0026#xfe0e;\n Technically you can aggregate all duplicate email addresses with jq, but you would have to handle the case, comma-separated addresses, and the \u0026quot;First Last \u0026lt;first.last@gmail.com\u0026gt;\u0026quot; notation. It\u0026rsquo;s merely an example after all. \u0026#x21a9;\u0026#xfe0e;\n If your Google account has 2-step verification activated, you will likely have to create and use an app password instead of your regular password. \u0026#x21a9;\u0026#xfe0e;\n If you retrieve your emails at a frequency lower than every 10 minutes, then you should also assign the same value of max-cache-ttl to default-cache-ttl. \u0026#x21a9;\u0026#xfe0e;\n   ","description":"","id":5,"section":"posts","tags":["emacs","notmuch","email","offlineimap"],"title":"Read and Compose Email in Emacs with Notmuch","uri":"https://firminmartin.com/en/posts/2020/10/read_email_in_emacs_with_notmuch/"},{"content":"Around 2016-2017, I used vimwiki a lot to take spare notes of Linux, programming \u0026amp; mathematics related topics. I moved from Vim to Emacs in June 2019 for the great Org mode and never came back. Recently, I wanted to get rid of my good old vimwiki directory and merge it in my org-mode personal wiki (using org-glaux). Since it\u0026rsquo;s a one-time task, I decided to use the only available outdated script then write some Emacs code to fix the result instead of patching the old script.\nPrelude: the power of vimwiki2org I looked for a vimwiki/Org converter, and luckily found a legacy Perl script (written 8 years ago). Well, it\u0026rsquo;s better than nothing. To install, as usual\n1 2 3  git clone https://github.com/fasheng/vimwiki2org cd vimwiki2org sudo make install   After tweaking available options a bit, I came up with this one-liner which outputs the whole vimwiki content into one single Org file vimwiki.org.\n1  vimwiki2org --no-ignore-lonely-header -L fix index.wiki \u0026gt; vimwiki.org   The option -L fix seems necessary to correctly detect subdirectories, such as diary/diary.wiki. The option --no-ignore-lonely-header was necessary to prevent some heading be commented out (for a good reason).\nInterlude: reworking the remaining Fix possible encoding issue An issue I have encountered was the failure to display correctly Unicode. If you have this issue, it means that some characters in the buffer cannot be rendered properly with Unicode. In my case, I have had a .png disguised as a vimwiki file output into vimwiki.org. That messes up the forthcoming steps.\nIf you are not sure, evaluate (M-:) the following snippet on the vimwiki.org buffer.\n1 2 3 4 5  (let ((str (decode-coding-string (buffer-string) \u0026#39;utf-8))) (erase-buffer) (insert str))   Now, save vimwiki.org. If there is a prompt asking you what encoding do you want to choose, then you should examine whether or not vimwiki.org contains weird stuff.\nRemove vimwiki TOC Auto-generated TOC by vimwiki seems unnecessary since Org mode produce TOC when exporting. It\u0026rsquo;s better to remove them as they create unexportable links. Inspired from this snippet, the following snippet removes the content of headline named Contents (i.e. TOCs auto-generated by vimwiki).\n1 2 3 4 5 6 7 8 9 10 11 12  (let* ((data (org-element-parse-buffer)) (str (progn (org-element-map data \u0026#39;headline (lambda (el) (when (equal (car-safe (org-element-property :title el)) \u0026#34;Contents\u0026#34;) ;; Here we remove the contents from this headline. (setf (nthcdr 2 el) nil)))) (org-element-interpret-data data)))) (erase-buffer) (insert str))   Then, a little \u0026ldquo;evil\u0026rdquo; regex %g/Contents/d cleans up the remaining empty TOC headlines. 1\nFix headlines Fix Java multiple lines comment I had a converted Java source block containing multi-lines comment like this\n1 2 3 4 5 6 7  #+begin_src java/* Comment * on * multiple * lines ********/ #+end_src   vimwiki2org didn\u0026rsquo;t put a comma before asterisk, and that messes up Org mode headlines. I have luckily only one such case, so I corrected it manually.\nFix source block I had some source blocks not correctly handled. Apparently, it\u0026rsquo;s possible that source block failed to convert when the content is in the same line that {{{. Fortunately, only one case hit me. Again, I fixed it manually, but it\u0026rsquo;s very easy to move one line down the content with regex.\nFix markup You may notice that code markup (i.e. `...`) failed to convert properly. A quick evil regex do the job: %s/`\\(.*?\\)`/~\\1~/g.\nFix mathematics equation Well, vimwiki inline \u0026amp; display style maths are not converted at all. To be short,\n {{$ ... }}$ corresponds to inline maths $ ... $ ; {{$%align% ... }}$ corresponds to maths environment \\[$\\begin{align} ... \\end{align}$\\].  And both of them can span on multiple lines.\nEvaluate the following evil regexps in order fixes respectively the previous issues:\n %s/{{\\$%\\(\\w*\\)%\\(\\(.\\|\\n\\)*?\\)}}\\$/\\\\[\\\\begin{\\1}\\2\\\\end{\\1}\\\\]/g %s/{{\\$\\(\\(.\\|\\n\\)*?\\)}}\\$/\\\\[\\1\\\\]/g  Move headline content in Org files The last step is optional, but in my opinion is better to move headlines in separated Org files as they was originally separated as vimwiki files.\nFix internal links We have to make link working again. Depending on whether you are using org-glaux, use one of the following evil regexps that suits you:\n Org mode file link: %s/\\[\\[\\(.*?\\)\\]\\[\\(.*?\\)\\]\\]/[[file:\\1.org][\\2]]/g org-glaux\u0026rsquo;s wiki link: %s/\\[\\[\\(.*?\\)\\]\\[\\(.*?\\)\\]\\]/[[wiki:../\\1][\\2]]/g  Separate contents in Org files If you have kept the outline of vimwiki2org output, i.e. each second-level headings corresponding to a vimwiki file, then the following snippet, inspired from this answer, will output the content of each second-level headline to a single Org file.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30  (defun my-org-export-each-headline (\u0026amp;optional scope) \u0026#34;Export each second-level headline to an Org file with the title as filename. If SCOPE is nil headlines in the current buffer are exported. For other valid values for SCOPE see `org-map-entries\u0026#39;. Already existing files are overwritten.\u0026#34; (interactive) ;; Widen buffer temporarily as narrowing would affect the exporting. (org-with-wide-buffer (save-mark-and-excursion ;; Loop through each headline. (org-map-entries (lambda () ;; Get the plain headline text without statistics and make filename. (when (equal (org-current-level) 2) (let* ((title (car (last (org-get-outline-path t)))) (dir (file-name-directory buffer-file-name)) (filename (concat dir title \u0026#34;.org\u0026#34;)) (content)) ;; Set the active region (set-mark (point)) (org-forward-heading-same-level 1) (activate-mark) (setq content (buffer-substring (region-beginning) (region-end))) ;; Export the region (with-temp-buffer (insert content) ;; Save the buffer to file and kill it. (write-file filename) (kill-current-buffer))))) nil scope))))   Postlude: how many links are broken ? This little section is reserved for org-glaux users, of whom I am the only one (for now!). After all those steps, we want to make sure that all internal links are correctly interconnected. This is as simple as calling M-x org-glaux-stats! That command produces a statistical overview of the current wiki including the number of broken links. As long as vimwiki files are under the same directories, no broken link is detected in my side. However, since we use relative links (see Fix internal links), they may be broken in the future as soon as they or their target Org files move. I plan to implement (not soon) a \u0026ldquo;safe move\u0026rdquo; feature inside org-glaux which preserves page\u0026rsquo;s link when page moves. But before that I should introduce caching (with e.g. l3kn/org-el-cache) to annihilate links resolving overheads.\n There is probably a better solution with org-element-map, but I\u0026rsquo;m not familiar enough with it. \u0026#x21a9;\u0026#xfe0e;\n   ","description":"","id":7,"section":"posts","tags":["vim","emacs","org-mode","org-glaux"],"title":"Migrate from vimwiki to Org mode","uri":"https://firminmartin.com/en/posts/2020/09/migrate_from_vimwiki_to_org-mode/"},{"content":"The most time-wasting thing when learning natural languages or reading literature works is nothing more than consulting a dictionary. During my studies, I came through three stages: paperback dictionary, online dictionary and Google Chrome search engines. The time requiring to consult one entry has decreased from a few minutes to dozens of seconds, but I’m still not satisfied with this speed.\n\n  Figure 1: A Kangxi Dictionary. It was quite fascinating to read when I was a child.\n  It happens it’s been around thirteen months that I moved from Vim to Emacs which means, in other words, that I handle all text-based file in Emacs. Naturally, I searched if there was such dictionary package for Emacs. Unsurprisingly, the author of Ivy, Oleh Krehel (a.k.a. abo-abo) has written an easy-to-use package named define-word for this purpose. In short, at each request it parses with regex an HTML page, retrieves the word definition and displays the result on minibuffer. A request can be made from a selected region or a prompted string.\n\n  Figure 2: Official screenshot of define-word\n  As I just started to work on my first ever package (org-glaux to be precise), I read the source code and learn how it is easy to write a new parser. Of course, that is due to the design made by abo-abo1. The first online dictionary I wanted to parse was Wiktionary2, but because of its wiki specificity, it has complex markup and hyperlink, so I gave up straight away. Then, I moved on to a Franco-Chinese dictionary I use from time to time. It works, but there was still some sporadic issues, such as looking up conjugated verb form doesn’t redirect to the verb definition but to the verb morphology. Also, the HTML layout was barely consistent, thus not very interesting to parse for what it provides.\nMy thoughts then turned to the Larousse dictionary. This French-French dictionary despite having the problem of one word might have multiple pages, it has not so many defects.\nMy thoughts then turned to the Larousse dictionary. This French-French dictionary, despite having the problem that one word might have multiple corresponding pages, it has not so many defects.\nAfter adding some utilities in the source code, such as HTML special characters decoding, the Larousse parser I wrote has finally highlighting for lexical class, examples and etymology (see figures 3 \u0026amp; 4).\nIf I spend more time on this, I would certainly be able to add some cool features like the possibility to search among multiple dictionaries, and even combine it to make flashcard with org-drill3. It is would be also good to add a few encyclopedias and synonym dictionaries during my spare time.\nLook up one word now takes an overhead of barely one second4. I\u0026rsquo;m quite happy with the result, but of course still open to a faster solution!\nYou can find here my fork implementing Larousse dictionary and test it by yourself.\n\n  Figure 3: Looking up the French word \u0026ldquo;couture\u0026rdquo; in Larousse dictionary.\n  \n  Figure 4: Looking up the French word \u0026ldquo;abandon\u0026rdquo; in Larousse dictionary.\n   According to the author, define-word only takes it 30 minutes to write. \u0026#x21a9;\u0026#xfe0e;\n At the time of writing, I realized that define-word supports now offline Wiktionary ! It suffices to download offline Wiktionary in ding format to use this feature. \u0026#x21a9;\u0026#xfe0e;\n And sync it in org-agenda by schedule it. \u0026#x21a9;\u0026#xfe0e;\n It\u0026rsquo;s a matter of pressing C-c d upon a word. \u0026#x21a9;\u0026#xfe0e;\n   ","description":"","id":9,"section":"posts","tags":["emacs","dictionary"],"title":"Consult dictionaries in Emacs","uri":"https://firminmartin.com/en/posts/2020/06/consult_dictionaries_in_emacs/"}]